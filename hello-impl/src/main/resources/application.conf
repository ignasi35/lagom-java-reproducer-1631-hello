play.modules.enabled += com.example.hello.impl.HelloModule

# Keeping this disabled should still produce "before-cluster-shutdown" as the "run-cs-from-phase"
# since that's the reasonable default for Lagom.
# Try different values to see them overwrite the default.
#play.akka.run-cs-from-phase = "before-cluster-shutdown"
#//play.akka.run-cs-from-phase = "service-unbind"
#//play.akka.run-cs-from-phase = "service-stop"


play.http.secret.key = "aksdjfhalskjfhasljkdfhalskjfhlj234712347qwert9a87dv78v69z7c69v7cxv69z7xcvzduvz"


## You can try this sample app starting multiple processes that form a cluster using the commands:
#  hello-impl/target/universal/stage/bin/hello-impl    -Dakka.remote.netty.tcp.port=2552       -Dhttp.port=9000
#  hello-impl/target/universal/stage/bin/hello-impl    -Dakka.remote.netty.tcp.port=2553       -Dhttp.port=9001
#  hello-impl/target/universal/stage/bin/hello-impl    -Dakka.remote.netty.tcp.port=2554       -Dhttp.port=9002
## Each command must be run from a different folder because Play pollutes to current directory with a RUNNING_PID file.

## disable 'lagom.cluster.join-self' when startig multiple processes manually.
akka {
  cluster {
    seed-nodes = [
      "akka.tcp://application@127.0.0.1:2552",
      "akka.tcp://application@127.0.0.1:2553",
      "akka.tcp://application@127.0.0.1:2554"]
  }
}

## You can run the sample app in a single-node MODE using the command
#  hello-impl/target/universal/stage/bin/hello-impl
## You'll have to enable 'join-self' below and disable the 'seed-nodes' above.
## Comment 'akka.cluster....' when startig a single process manually.
lagom.cluster {
  ## Used to test with single-node clusters. Once the process is running, use `jconsole` to connet via JMX
  ## and send a manual downing using the "akka" MBean-Operation "down(akka.tcp://application@192.168.1.133:2552)"
  ## (your Address may vary, your service logs)
  join-self = off
  ## JVM exit is responsibility of Play, not Akka, but when downing the responsiblity shifts and
  ## we must enable tell Akka to take over. The reason is that the trigger is no longer a SIGTERM but a Downing
  ## event handled by Akka directly. The implication is we have to manually register a shutdown task in JoinClusterImpl
  ## and (manually) decide if we want to trogger the system.exit which, in turn, will invoke Play's JVM shutdown hook.
  ## The end result is that all resources will be released but not in the nicest of the orders but since we're
  ## Downed and no longer have access to the cluster it's not a big deal.
  exit-jvm-when-system-terminated = on
}



akka.cluster.downing-provider-class = "com.lightbend.akka.sbr.SplitBrainResolverProvider"
# To enable the split brain resolver you first need to enable the provider in your application.conf:
# akka.cluster.downing-provider-class = "com.lightbend.akka.sbr.SplitBrainResolverProvider"

akka.cluster.split-brain-resolver {
  # Select one of the available strategies (see descriptions below):
  # static-quorum, keep-majority, keep-oldest, keep-referee
  # if left "off" when the downing provider is enabled cluster startup will fail.
  active-strategy = keep-majority

  # Time margin after which shards or singletons that belonged to a downed/removed
  # partition are created in surviving partition. The purpose of this margin is that
  # in case of a network partition the persistent actors in the non-surviving partitions
  # must be stopped before corresponding persistent actors are started somewhere else.
  # This is useful if you implement downing strategies that handle network partitions,
  # e.g. by keeping the larger side of the partition and shutting down the smaller side.
  # Decision is taken by the strategy when there has been no membership or
  # reachability changes for this duration, i.e. the cluster state is stable.
  stable-after = 5s
}
